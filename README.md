# TreeAgent ğŸŒ³ğŸ¤– (MVP)

TreeAgent is a tiny, work-in-progress experiment in **hierarchical, multi-agent orchestration** for code-generation tasks.  
It is maintained by a single developer and **has not been run, profiled, or tested end-to-end yet**. Expect breaking changes and dragons. ğŸ‰

---

## âœ¨ Project Goal

*Create an â€œAI engineering treeâ€ where a **root agent** (the â€œPrincipal Engineerâ€) decomposes a user request into subtasks,  
hands them to **planner** and **executor** child agents, and bubbles results back upâ€”all on consumer hardware, entirely offline if desired.*

Why bother?

1. **Deliberate planning.** Test-time tree structures let small models explore alternative plans instead of committing to the first idea.  
2. **Isolation & safety.** Each node operates with a minimal toolset and context window, keeping accidental prompt leaks and runaway costs in check.  
3. **Modularity.** Nodes live in their own Python packages so they can be swapped, parallelised, or rate-limited independently.

---

## ğŸ—ºï¸ Current Status (Pre-Alpha)

| Area            | State | Notes |
|-----------------|-------|-------|
| Core data models (`Task`, `ModelResponse`) | âœ… Drafted | Pydantic schemas in `src/dataModel/` |
| Recursive orchestration (`AgentOrchestrator`)           | âœ… First pass | Needs error handling & logging |
| Parallel execution logic                                | ğŸŸ¡ Prototype | Sibling-task **non-concurrency** still WIP |
| CLI / entry-point                                      | ğŸŸ¥ Todo | Basic `python -m treeagent â€¦` runner planned |
| Tests & CI                                             | ğŸŸ¥ Todo | No unit tests yet |
| Docs / examples                                        | ğŸŸ¥ Todo | This README is step 1 |

---

## ğŸš€ Quick Start

```bash
git clone https://github.com/JPrier/TreeAgent.git
cd TreeAgent
python3.11 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt   # very small for now
python -m treeagent.demo          # stub script prints skeleton task tree
```

> Heads-up: youâ€™ll need an OpenAI (or other) API key in your shell once the first agent stubs call an LLM.


## ğŸ§® Repository Structure
```bash
TreeAgent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ dataModel/          # pydantic task / response schemas
â”‚   â””â”€â”€ ...
â”œâ”€â”€ examples/               # minimal end-to-end scenarios (coming soon)
â”œâ”€â”€ tests/                  # pytest suite
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Spawn Rules Configuration

Agent spawning behaviour is controlled by a JSON file named
`spawn_rules.json`. The orchestrator looks for this file in `config/` or the
current working directory. Each task type lists which child types it may
create and the maximum number allowed:

```json
{
  "HLD": { "can_spawn": { "LLD": 5, "RESEARCH": 5, "TEST": 1 }, "self_spawn": false },
  "LLD": { "can_spawn": { "IMPLEMENT": 5, "RESEARCH": 3, "TEST": 1 }, "self_spawn": false }
}
```

Adjust these numbers to experiment with deeper or shallower trees.

## ğŸ§ª Running Tests

Install the optional dev dependencies to enable coverage reporting:

```bash
pip install -e .[dev] pytest
```

Execute the suite with coverage enabled:

```bash
pytest --cov=src
```

### Resuming From Checkpoints

Each project run writes snapshots to the directory specified by
`--checkpoint-dir` (defaults to `checkpoints`). If the process stops you can
continue where it left off:

```bash
python -m treeagent.cli --resume checkpoints/20240101010101
```

The orchestrator will load the latest snapshot in that directory and resume
processing the remaining tasks.

## ğŸ›£ï¸ Roadmap
1. Minimal runnable demo â€“ wire up a root â†’ planner â†’ executor flow that prints a toy result.

2. Deterministic retries â€“ enforce schema-valid responses via structured-output loops.

3. Sandboxed execution â€“ run generated code in a subprocess with time & memory limits.

4. CLI + config files â€“ YAML or TOML to pick local vs. cloud models and set parallelism hints.

5. Metrics & logging â€“ capture token counts, wall-clock time, and per-node error traces.

6. Extensible UI â€“ optional graph-viz or web dashboard to visualise task trees.
